{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Feature_Extracition.csv', index_col= 'Unnamed: 0')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['SOFA score'].apply(lambda x: 0 if x < 12 else 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data= df, x= 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (39, 15), facecolor='white')\n",
    "for i, col in enumerate(df):\n",
    "    plt.subplot(5, 13, i+1)\n",
    "    sns.boxplot(data= df, x= 'label', y = f'{col}')\n",
    "    plt.title(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature selection + Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# StarifiedKfold\n",
    "def Starifieds(df_feature_cl, pure_feature, random_state= 42, n_splits= 4, shuffle= True):\n",
    "\n",
    "    #======================================\n",
    "    # 用處: Starifieds Kflod 原本只能出index，這裡二合一\n",
    "    #\n",
    "    # Parameter: \n",
    "    #     df_feature_cl, feature\n",
    "    #     pure_feature, label\n",
    "    #     random_state= 42, 不必多說\n",
    "    #     n_splits= 4,  分幾份\n",
    "    #     shuffle= True  如字面上\n",
    "    #======================================\n",
    "\n",
    "    # 先創StratifiedKFold 然後再 .split() 然後取第一個\n",
    "    xtrain, xtest = list(StratifiedKFold(n_splits= n_splits, shuffle= shuffle, random_state= random_state).split(df_feature_cl, pure_feature))[0]\n",
    "\n",
    "    # 把index(用iloc給row的方式)\n",
    "    train_fea, test_fea = df_feature_cl.iloc[xtrain], df_feature_cl.iloc[xtest]\n",
    "    train_label, test_label = pure_feature.iloc[xtrain], pure_feature.iloc[xtest]\n",
    "\n",
    "    return train_fea, train_label, test_fea, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns= ['label', 'SOFA score'])\n",
    "label = df['label']\n",
    "\n",
    "\n",
    "x_train, label_train, x_test, label_test = Starifieds(X, label, shuffle=True, random_state=42)\n",
    "\n",
    "label_train, label_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "# feature selection\n",
    "\n",
    "def ttttest(train_fea, train_label):\n",
    "\n",
    "    #======================================================\n",
    "    # 1. scipy.stats.shapiro\n",
    "    shap_low = []\n",
    "    shap_high = []\n",
    "    shap_cols = []\n",
    "\n",
    "    all_fea = train_fea.merge(train_label, left_index= True, right_index= True)\n",
    "    all_fea = all_fea.sort_values(by= train_label.name)\n",
    "\n",
    "    # print(train_label.name)\n",
    "\n",
    "    cols = all_fea.columns\n",
    "    #print(cols)\n",
    "\n",
    "    all_low = all_fea[all_fea[train_label.name] == 0]\n",
    "    all_high = all_fea[all_fea[train_label.name] == 1]\n",
    "\n",
    "    for col in cols:\n",
    "        # 看p_value 可不留\n",
    "        lows = scipy.stats.shapiro(all_low[col])[1]\n",
    "        highs = scipy.stats.shapiro(all_high[col])[1]\n",
    "\n",
    "        shap_low.append(lows)\n",
    "        shap_high.append(highs)\n",
    "\n",
    "        if lows > 0.05 and highs > 0.05:\n",
    "            shap_cols.append(col)\n",
    "\n",
    "    shap_cols\n",
    "    #=====================================================\n",
    "    # 2.scipy.stats.levene\n",
    "\n",
    "    levene = []\n",
    "    good_levene = []\n",
    "\n",
    "    for shapiro_col in shap_cols:\n",
    "\n",
    "        lev = scipy.stats.levene(all_low[shapiro_col], all_high[shapiro_col], center = 'mean')[1]  \n",
    "        levene.append(lev)\n",
    "\n",
    "        if lev > 0.05:\n",
    "            good_levene.append(shapiro_col)\n",
    "\n",
    "    good_levene\n",
    "\n",
    "    #======================================================\n",
    "    # 3. scipy.stats.ttest_ind\n",
    "    \n",
    "    ttest = []\n",
    "    good_ttest = []\n",
    "\n",
    "\n",
    "    for good_lev in good_levene:\n",
    "        ttestn = scipy.stats.ttest_ind(all_low[good_lev], all_high[good_lev], equal_var = True)[1]\n",
    "        ttest.append(ttestn)\n",
    "\n",
    "    #display results\n",
    "    ttest_df = pd.Series(ttest, index= good_levene, name= train_label.name + '_T_score').sort_values()\n",
    "    return ttest_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_plot(test_feature, test_label, train_fea, train_label,  model, h = 0.02, bound= 1,  **params):\n",
    "\n",
    "    # plot function\n",
    "    #===========================================#\n",
    "    #用途: 畫出邊界plot\n",
    "    \n",
    "    #切記: 二維才能畫圖\n",
    "    #===========================================#\n",
    "    # Import: \n",
    "    # numpy\n",
    "    # matplotlib.pyplot\n",
    "    #===========================================#\n",
    "\n",
    "    # 白底\n",
    "    plt.style.use('seaborn-white')\n",
    "    sns.set(font_scale=1.4)\n",
    "\n",
    "    # 確定是二維\n",
    "    if len(test_feature.columns) == 2:\n",
    "        # 把網格架好\n",
    "        def make_meshgrid(x1, x2, h = h):\n",
    "            x_min, x_max = x1.min() - bound, x1.max() + bound\n",
    "            y_min, y_max = x2.min() - bound, x2.max() + bound\n",
    "            xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "            return xx, yy\n",
    "        \n",
    "        # 畫出等高線\n",
    "        def plot_contours(clf, xx, yy, ax, **params ):\n",
    "            z = clf.predict(np.c_[xx.ravel(), yy.ravel()])  #np.c_ 帥爛\n",
    "            z = z.reshape(xx.shape)\n",
    "            ax.contourf(xx, yy, z, alpha= 0.8, cmap = plt.cm.coolwarm)\n",
    "            ax.set_xlim(xx.min(), xx.max())\n",
    "            ax.set_ylim(yy.min(), yy.max())\n",
    "                        \n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize= (12, 6))\n",
    "\n",
    "        # 要用test的 還是train的\n",
    "        xx, yy = make_meshgrid(test_feature.iloc[:, 0],  test_feature.iloc[:, 1])\n",
    "        \n",
    "\n",
    "        plot_contours(model, xx, yy, cmap=plt.cm.coolwarm, ax= ax1, **params)\n",
    "        ax1.scatter(train_fea.iloc[:, 0], train_fea.iloc[:, 1], c= train_label, cmap=plt.cm.coolwarm)  # 用label拚座標，暈爛\n",
    "        ax1.set_xlabel(train_fea.columns[0])\n",
    "        ax1.set_ylabel(train_fea.columns[1])\n",
    "        ax1.set_title(f\"{model.__class__.__name__} Train Plot {accuracy_score(train_label, model.predict(train_fea))}\")\n",
    "\n",
    "\n",
    "        plot_contours(model, xx, yy, cmap=plt.cm.coolwarm, ax= ax2,  **params)\n",
    "        ax2.scatter(test_feature.iloc[:, 0], test_feature.iloc[:, 1], c= test_label, cmap=plt.cm.coolwarm)  # 用label拚座標，暈爛\n",
    "        ax2.set_xlabel(test_feature.columns[0])\n",
    "        ax2.set_ylabel(test_feature.columns[1])\n",
    "        ax2.set_title(f\"{model.__class__.__name__} Test Plot {accuracy_score(test_label, model.predict(test_feature))}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    else: \n",
    "        print(\"Data should be two dimension!!\")\n",
    "\n",
    "        # pass\n",
    "\n",
    "    #==================R=O=C===================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condusion_m(test_fea, test_label, model):\n",
    "\n",
    "    #=============================\n",
    "    # 用途: \n",
    "    #     製造出confusion matrix\n",
    "\n",
    "    # Parameter:\n",
    "    #     test_fea  就feature\n",
    "    #     test_label  就label\n",
    "    #     model  就model\n",
    "    #=============================\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    conf = confusion_matrix(test_label, model.predict(test_fea))\n",
    "    conp = np.array([(x/sum(x)) for x in conf])\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize= (14, 7))\n",
    "    # 重點是 annot，cmap='Blues'\n",
    "    sns.set(font_scale=1.8)\n",
    "    sns.heatmap(conp , annot= True, cmap='Blues', ax= ax1)\n",
    "    ax1.set_title(f\"CM of {model.__class__.__name__}\")\n",
    "\n",
    "    sns.heatmap(conf , annot= True, cmap='Blues', ax= ax2)\n",
    "    ax2.set_title(f\"CM of {model.__class__.__name__}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROCP(test_fea, test_label, model, a= 0, pos_label= 0):\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "    #=============================\n",
    "    # 用途: \n",
    "    #     製造出confusion matrix\n",
    "\n",
    "    # Parameter:\n",
    "    #     test_fea  就feature\n",
    "    #     test_label  就label\n",
    "    #     model  就model\n",
    "    #     a= 0 如果auc很奇怪，就 =1 \n",
    "    #=============================\n",
    "\n",
    "    try:\n",
    "        prob = model.predict_proba(test_fea)[:, a]\n",
    "        sns.set(font_scale=1.4)\n",
    "        fig, ax= plt.subplots(1, 1, figsize= (8, 7))\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(test_label, prob, pos_label= pos_label)  #pos_label= 0 要設值\n",
    "        plt.plot(fpr, tpr,   color= 'b', linewidth=3.0)\n",
    "\n",
    "        \n",
    "        x, y = np.arange(0, 1, 0.01), np.arange(0, 1, 0.01)\n",
    "        plt.plot(x, y, '-.', linewidth=3.0, label= f\"AUC  = {auc(fpr, tpr)}\", color= 'r')\n",
    "        \n",
    "        ax.set_xlabel(\" 1 - specificity\")\n",
    "        ax.set_ylabel(\"Sensitivity\")\n",
    "        ax.set_title(f\"{model.__class__.__name__}'s  ROC\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    except:\n",
    "        print(\"Can't print ROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from itertools import combinations\n",
    "\n",
    "for iui in range(1000):\n",
    "    print(iui, end= \" \")\n",
    "    train_feas1, train_labels, test_feas1, test_labels = Starifieds(X, label, random_state= iui)    \n",
    "# try:\n",
    "    cbi2 = ttttest(train_feas1, train_labels)\n",
    "    goods = cbi2[cbi2 < 0.05]\n",
    "    \n",
    "    # print(goods)\n",
    "    comb = combinations(goods.index, 2)\n",
    "    # print(list(comb))\n",
    "    \n",
    "\n",
    "    # if cbi2[0] < 0.05 and cbi2[1] < 0.05:\n",
    "    for good_feature in list(comb):     \n",
    "           \n",
    "        train_feas, test_feas = train_feas1[list(good_feature)], test_feas1[list(good_feature)]    \n",
    "\n",
    "        # ====================\n",
    "        # print(train_feas.columns)\n",
    "        for imm in train_feas.columns:\n",
    "            if 'std' not in imm:     \n",
    "                sd = StandardScaler()\n",
    "                train_feasn = sd.fit_transform(train_feas[imm].values.reshape(-1,1))\n",
    "                test_feasn = sd.transform(test_feas[imm].values.reshape(-1,1))\n",
    "\n",
    "                train_feas[imm] = train_feasn\n",
    "                test_feas[imm] = test_feasn\n",
    "\n",
    "                # print(f'trans {imm}')\n",
    "        # print(test_feas)\n",
    "        # ===================================\n",
    "\n",
    "        \n",
    "        param_grid = {\"C\": [0.01, 0.1, 1, 10, 100], \"gamma\":[0.01, 0.1, 1, 5]}\n",
    "\n",
    "        param_list = list(ParameterSampler(param_grid, n_iter=10000))\n",
    "\n",
    "        for par in param_list:\n",
    "            csc = SVC(probability=True, **par)                          \n",
    "        \n",
    "        #gc = GridSearchCV(csc, params, cv= 5, n_jobs= -1, scoring= 'accuracy')\n",
    "            csc.fit(train_feas, train_labels)\n",
    "            train_s = accuracy_score(train_labels, csc.predict(train_feas))\n",
    "            test_s = accuracy_score(test_labels, csc.predict(test_feas))\n",
    "            \n",
    "            recalls = recall_score(test_labels, csc.predict(test_feas))\n",
    "\n",
    "        # pred = gc.best_estimator_.predict(test_feas)\n",
    "            if test_s  >= 0.79 and train_s  >= 0.75 and test_s < 1 and train_s < 1 and recalls >= 0.68:\n",
    "                print('rand = ', iui)\n",
    "                print(cbi2.loc[list(good_feature)])\n",
    "                \n",
    "                # print(\"train \", gc.best_score_)\n",
    "                print('train ', train_s)\n",
    "                print('test', test_s)\n",
    "                print(\"par = \", par)\n",
    "\n",
    "                \n",
    "                print('Recall ', recalls)\n",
    "\n",
    "                print(goods)\n",
    "\n",
    "                acc_plot(test_feas, test_labels, train_feas, train_labels, csc)\n",
    "                condusion_m(test_feas, test_labels, csc)\n",
    "                ROCP(test_feas, test_labels, csc, a= 0)\n",
    "    # except:\n",
    "    #     pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 做一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iui = 750\n",
    "good_feature = ['tHb_begin_slope_stage1', 'HHb_mean_diff_stage2']\n",
    "par =  {'gamma': 1, 'C': 10}\n",
    "\n",
    "train_feas1, train_labels, test_feas1, test_labels = Starifieds(X, label, random_state= iui)    \n",
    "\n",
    "cbi2 = ttttest(train_feas1, train_labels)\n",
    "goods = cbi2[cbi2 < 0.05]\n",
    "    \n",
    "train_feas, test_feas = train_feas1[list(good_feature)], test_feas1[list(good_feature)]    \n",
    "\n",
    "# ====================\n",
    "# print(train_feas.columns)\n",
    "for imm in train_feas.columns:\n",
    "    if 'std' not in imm:     \n",
    "        sd = StandardScaler()\n",
    "        train_feasn = sd.fit_transform(train_feas[imm].values.reshape(-1,1))\n",
    "        test_feasn = sd.transform(test_feas[imm].values.reshape(-1,1))\n",
    "\n",
    "        train_feas[imm] = train_feasn\n",
    "        test_feas[imm] = test_feasn\n",
    "\n",
    "        # print(f'trans {imm}')\n",
    "# print(test_feas)\n",
    "# ===================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "csc = SVC(probability=True, **par)                          \n",
    "\n",
    "#gc = GridSearchCV(csc, params, cv= 5, n_jobs= -1, scoring= 'accuracy')\n",
    "csc.fit(train_feas, train_labels)\n",
    "train_s = accuracy_score(train_labels, csc.predict(train_feas))\n",
    "test_s = accuracy_score(test_labels, csc.predict(test_feas))\n",
    "\n",
    "recalls = recall_score(test_labels, csc.predict(test_feas))\n",
    "\n",
    "\n",
    "print('rand = ', iui)\n",
    "print(cbi2.loc[list(good_feature)])\n",
    "\n",
    "# print(\"train \", gc.best_score_)\n",
    "print('train ', train_s)\n",
    "print('test', test_s)\n",
    "print(\"par = \", par)\n",
    "\n",
    "\n",
    "print('Recall ', recalls)\n",
    "\n",
    "print(goods)\n",
    "\n",
    "acc_plot(test_feas, test_labels, train_feas, train_labels, csc)\n",
    "condusion_m(test_feas, test_labels, csc)\n",
    "ROCP(test_feas, test_labels, csc, a= 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 看特徵是否長不一樣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted = df[['tHb_begin_slope_stage1', 'HHb_mean_diff_stage2', 'label']]\n",
    "wanted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "sns.boxplot(data=wanted, x= 'label', y= 'tHb_begin_slope_stage1')\n",
    "plt.xticks([0, 1], ['Low', 'High'])\n",
    "plt.xlabel('Group')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "sns.boxplot(data=wanted, x= 'label', y= 'HHb_mean_diff_stage2')\n",
    "plt.xticks([0, 1], ['Low', 'High'])\n",
    "plt.xlabel('Group')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
