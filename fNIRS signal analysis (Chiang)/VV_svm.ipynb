{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roadmap\n",
    "1. 特徵萃取 (學姊) (含濾波歸一化) 不用生理資訊(BMI、AGE)\n",
    "2. ttest\n",
    "3. 標準化\n",
    "4. SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import ParameterSampler, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#scipy\n",
    "import scipy.stats\n",
    "\n",
    "#sql\n",
    "import pymysql\n",
    "\n",
    "#warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"VV_after_norm.csv\")\n",
    "df = df.drop(columns=[\"date\", 'No'])\n",
    "label = df['Label']\n",
    "feature = df.drop(columns= 'Label')\n",
    "feature.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby('No').count()['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_plot(data_fea, data_label, train_fea, train_label,  model, h = 0.02, bound= 1,  **params):\n",
    "\n",
    "    # plot function\n",
    "    #===========================================#\n",
    "    #用途: 畫出邊界plot\n",
    "\n",
    "    #切記: 二維才能畫圖\n",
    "    #===========================================#\n",
    "    # Import: \n",
    "    # numpy\n",
    "    # matplotlib.pyplot\n",
    "    #===========================================#\n",
    "\n",
    "    plt.style.use('seaborn-white')\n",
    "\n",
    "    if len(data_fea.columns) == 2:\n",
    "        def make_meshgrid(x1, x2, h = h):\n",
    "            x_min, x_max = x1.min() - bound, x1.max() + bound\n",
    "            y_min, y_max = x2.min() - bound + 1, x2.max() + bound - 1\n",
    "            xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "            return xx, yy\n",
    "\n",
    "        def plot_contours(clf, xx, yy, ax, **params ):\n",
    "            z = clf.predict(np.c_[xx.ravel(), yy.ravel()])  #np.c_ 帥爛\n",
    "            z = z.reshape(xx.shape)\n",
    "            ax.contourf(xx, yy, z, alpha= 0.8, cmap = plt.cm.coolwarm)\n",
    "            ax.set_xlim(xx.min(), xx.max())\n",
    "            ax.set_ylim(yy.min(), yy.max())\n",
    "            \n",
    "        sns.set(font_scale=1.4)\n",
    "\n",
    "        fig, (ax2, ax1) = plt.subplots(1, 2, figsize= (12, 6))\n",
    "        xx, yy = make_meshgrid(data_fea.iloc[:, 0],  data_fea.iloc[:, 1])\n",
    "        plot_contours(model, xx, yy, cmap=plt.cm.coolwarm, ax= ax1,  **params)\n",
    "        ax1.scatter(data_fea.iloc[:, 0], data_fea.iloc[:, 1], c= data_label, cmap=plt.cm.coolwarm)  # 用label拚座標，暈爛\n",
    "        ax1.set_xlabel(data_fea.columns[0])\n",
    "        ax1.set_ylabel(data_fea.columns[1])\n",
    "        ax1.set_title(f\"VV Group {model.__class__.__name__} Accuracy: {accuracy_score(test_labels, model.predict(data_fea)):.3f} (Test)\")\n",
    "        # plt.show()\n",
    "\n",
    "        # plt.figure(figsize= (6, 6))\n",
    "        plot_contours(model, xx, yy, cmap=plt.cm.coolwarm, ax= ax2, **params)\n",
    "        ax2.scatter(train_fea.iloc[:, 0], train_fea.iloc[:, 1], c= train_label, cmap=plt.cm.coolwarm)  # 用label拚座標，暈爛\n",
    "        ax2.set_xlabel(train_fea.columns[0])\n",
    "        ax2.set_ylabel(train_fea.columns[1])\n",
    "        ax2.set_title(f\"VV Group {model.__class__.__name__} Accuracy: {accuracy_score(train_label, model.predict(train_fea)):.3f} (Train)\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    else: \n",
    "        print(\"Data should be two dimension!!\")\n",
    "\n",
    "        pass\n",
    "\n",
    "    #==================R=O=C===================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condusion_m(test_fea, test_label, model, plot= True, types= \"Test\"):\n",
    "\n",
    "    #=============================\n",
    "    # 用途: \n",
    "    #     製造出confusion matrix\n",
    "\n",
    "    # Parameter:\n",
    "    #     test_fea  就feature\n",
    "    #     test_label  就label\n",
    "    #     model  就model\n",
    "    #=============================\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    conf = confusion_matrix(test_label, model.predict(test_fea))\n",
    "    conp = np.array([(x/sum(x)) for x in conf])\n",
    "\n",
    "    # fig, (ax1, ax2) = plt.subplots(1, 2, figsize= (14, 7))\n",
    "    # 重點是 annot，cmap='Blues'\n",
    "    if plot:\n",
    "        sns.set(font_scale=1.8)\n",
    "        sns.heatmap(conp , annot= True, cmap='Blues', xticklabels= ['LOW', 'HIGH'], yticklabels=['LOW', 'HIGH'])\n",
    "        plt.title(f\"Confusion Matrix of VV Group ({types})\")\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.show()\n",
    "\n",
    "        sns.heatmap(conf , annot= True, cmap='Blues', xticklabels= ['LOW', 'HIGH'], yticklabels=['LOW', 'HIGH'])\n",
    "        plt.title(f\"Confusion Matrix of VV Group ({types})\")\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    sensitivity = recall_score(test_label, model.predict(test_fea))\n",
    "    precision = precision_score(test_label, model.predict(test_fea))\n",
    "    return sensitivity, precision\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROCP(test_fea, test_label, model, a= 0, pos_label= 0):\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "    #=============================\n",
    "    # 用途: \n",
    "    #     製造出confusion matrix\n",
    "\n",
    "    # Parameter:\n",
    "    #     test_fea  就feature\n",
    "    #     test_label  就label\n",
    "    #     model  就model\n",
    "    #     a= 0 如果auc很奇怪，就 =1 \n",
    "    #=============================\n",
    "\n",
    "    try:\n",
    "        prob = model.predict_proba(test_fea)[:, a]\n",
    "        sns.set(font_scale=1.4)\n",
    "        fig, ax= plt.subplots(1, 1, figsize= (8, 7))\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(test_label, prob, pos_label= pos_label)  #pos_label= 0 要設值\n",
    "        plt.plot(fpr, tpr,   color= 'b', linewidth=3.0)\n",
    "\n",
    "        \n",
    "        x, y = np.arange(0, 1, 0.01), np.arange(0, 1, 0.01)\n",
    "        plt.plot(x, y, '-.', linewidth=3.0, label= f\"AUC  = {auc(fpr, tpr)}\", color= 'r')\n",
    "        \n",
    "        ax.set_xlabel(\" 1 - specificity\")\n",
    "        ax.set_ylabel(\"Sensitivity\")\n",
    "        ax.set_title(f\"{model.__class__.__name__}'s  ROC\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    except:\n",
    "        print(\"Can't print ROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttttest(train_fea, train_label):\n",
    "\n",
    "    #======================================================\n",
    "    # 1. scipy.stats.shapiro\n",
    "\n",
    "\n",
    "    shap_low = []\n",
    "    shap_high = []\n",
    "    shap_cols = []\n",
    "\n",
    "    all_fea = train_fea.merge(train_label, left_index= True, right_index= True)\n",
    "    # all_fea = all_fea.sort_values(by= train_label.name)\n",
    "\n",
    "    # print(train_label.name)\n",
    "\n",
    "    cols = all_fea.columns\n",
    "    #print(cols)\n",
    "\n",
    "    all_low = all_fea[all_fea[train_label.name] == 0]\n",
    "    all_high = all_fea[all_fea[train_label.name] == 1]\n",
    "\n",
    "    for col in cols:\n",
    "        # 看p_value 可不留\n",
    "        lows = scipy.stats.shapiro(all_low[col])[1]\n",
    "        highs = scipy.stats.shapiro(all_high[col])[1]\n",
    "\n",
    "        shap_low.append(lows)\n",
    "        shap_high.append(highs)\n",
    "\n",
    "        if lows > 0.05 and highs > 0.05:\n",
    "            shap_cols.append(col)\n",
    "\n",
    "    shap_cols\n",
    "    #=====================================================\n",
    "    # 2.scipy.stats.levene\n",
    "\n",
    "    levene = []\n",
    "    good_levene = []\n",
    "\n",
    "    for shapiro_col in shap_cols:\n",
    "\n",
    "        lev = scipy.stats.levene(all_low[shapiro_col], all_high[shapiro_col], center = 'mean')[1]  \n",
    "        levene.append(lev)\n",
    "\n",
    "        if lev > 0.05:\n",
    "            good_levene.append(shapiro_col)\n",
    "\n",
    "    good_levene\n",
    "\n",
    "    #======================================================\n",
    "    # 3. scipy.stats.ttest_ind\n",
    "    \n",
    "    ttest = []\n",
    "    good_ttest = []\n",
    "\n",
    "\n",
    "    for good_lev in good_levene:\n",
    "        ttestn = scipy.stats.ttest_ind(all_low[good_lev], all_high[good_lev], equal_var = True)[1]\n",
    "        ttest.append(ttestn)\n",
    "\n",
    "    #display results\n",
    "    ttest_df = pd.Series(ttest, index= good_levene, name= train_label.name + '_T_score').sort_values()\n",
    "    return ttest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StarifiedKfold\n",
    "def Starifieds(df_feature_cl, pure_feature, random_state= 42, n_splits= 4, shuffle= True):\n",
    "\n",
    "    #======================================\n",
    "    # 用處: Starifieds Kflod 原本只能出index，這裡二合一\n",
    "    #\n",
    "    # Parameter: \n",
    "    #     df_feature_cl, feature\n",
    "    #     pure_feature, label\n",
    "    #     random_state= 42, 不必多說\n",
    "    #     n_splits= 4,  分幾份\n",
    "    #     shuffle= True  如字面上\n",
    "    #======================================\n",
    "\n",
    "    xtrain, xtest = list(StratifiedKFold(n_splits= n_splits, shuffle= shuffle, random_state= random_state).split(df_feature_cl, pure_feature))[0]\n",
    "    train_fea, test_fea = df_feature_cl.iloc[xtrain], df_feature_cl.iloc[xtest]\n",
    "    train_label, test_label = pure_feature.iloc[xtrain], pure_feature.iloc[xtest]\n",
    "\n",
    "    #===============\n",
    "    \n",
    "\n",
    "    try:\n",
    "        train_fea.drop(columns= [\"Gender\"], inplace=True)\n",
    "        test_fea.drop(columns= [\"Gender\"], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return train_fea, train_label, test_fea, test_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fea, train_label, test_fea, test_label = Starifieds(feature, label, random_state=40, n_splits=4, shuffle= True)\n",
    "\n",
    "for rand in range(40):\n",
    "    train_fea2, train_label2, test_fea2, test_label2 = train_fea, train_label, test_fea, test_label = Starifieds(feature, label, random_state=rand, n_splits=4, shuffle= True)\n",
    "\n",
    "    cbi2 = ttttest(train_fea2, train_label2)\n",
    "    # print(cbi2)\n",
    "    if cbi2[0] < 0.05 and cbi2[1] < 0.05:\n",
    "        print(\"rand \", rand, \"\\n\", cbi2[:2], end= '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pymysql.connect(host= '127.0.0.1', port= 3306, user= 'root', passwd='****', charset= 'utf8', db= 'svm')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor.close()\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_string = str(pd.to_datetime('today').replace(microsecond = 0)).replace(\" \", \"\").replace(\"-\", \"\").replace(\":\", \"\")\n",
    "\n",
    "create_command = '''CREATE table VV{}(ID INT AUTO_INCREMENT, feature_1 varchar(1000), p_value_feature_1 decimal(8, 4), feature_2 varchar(1000), p_value_feature_2 decimal(8, 4), rand int, train_score decimal(8, 4), test_score decimal(8, 4), gamma decimal(8, 4), C decimal(8, 4),sensitivity decimal(8, 4), precision_col decimal(8, 4), ttest varchar(3000), PRIMARY KEY (ID))default charset= utf8;'''.format(time_string)\n",
    "\n",
    "cursor.execute(create_command)\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iui in range(2000):\n",
    "    print(iui, end= \" \")\n",
    "    train_feas, train_labels, test_feas, test_labels = Starifieds(feature, label, random_state=iui, n_splits=4, shuffle= True)\n",
    "    # try:\n",
    "    cbi2 = ttttest(train_feas, train_labels)\n",
    "    if cbi2[0] < 0.05 and cbi2[1] < 0.05:\n",
    "        \n",
    "        train_feas, test_feas = train_feas[cbi2.index[:2]], test_feas[cbi2.index[:2]]\n",
    "\n",
    "        train_f1 = train_feas.columns[0]\n",
    "        train_f2 = train_feas.columns[1]\n",
    "\n",
    "        # ====================\n",
    "        # print(train_feas.columns)\n",
    "        for imm in train_feas.columns:\n",
    "            if 'std' not in imm:     \n",
    "                sd = StandardScaler()\n",
    "                train_feasn = sd.fit_transform(train_feas[imm].values.reshape(-1,1))\n",
    "                test_feasn = sd.transform(test_feas[imm].values.reshape(-1,1))\n",
    "\n",
    "                train_feas[imm] = train_feasn\n",
    "                test_feas[imm] = test_feasn\n",
    "\n",
    "                # print(f'trans {imm}')\n",
    "        # print(test_feas)\n",
    "        # ===================================\n",
    "\n",
    "        \n",
    "        param_grid = {\"C\": [0.01, 0.1, 1, 10, 100], \"gamma\":[0.01, 0.1, 1, 5]}\n",
    "\n",
    "        param_list = list(ParameterSampler(param_grid, n_iter=10000))\n",
    "\n",
    "        for par in param_list:\n",
    "            csc = SVC(probability=True, **par)                          \n",
    "        \n",
    "        #gc = GridSearchCV(csc, params, cv= 5, n_jobs= -1, scoring= 'accuracy')\n",
    "            csc.fit(train_feas, train_labels)\n",
    "            train_s = accuracy_score(train_labels, csc.predict(train_feas))\n",
    "            test_s = accuracy_score(test_labels, csc.predict(test_feas))\n",
    "\n",
    "\n",
    "\n",
    "            if test_s  >= 0.795 and train_s  >= 0.795 and test_s < 0.95 and train_s < 0.95:                \n",
    "                print('rand = ', iui)\n",
    "                print(cbi2)\n",
    "                \n",
    "                # print(\"train \", gc.best_score_)\n",
    "                print('train ', train_s)\n",
    "                print('test', test_s)\n",
    "                print(\"par = \", par)\n",
    "\n",
    "                cmrr = condusion_m(test_feas, test_labels, csc, False)\n",
    "                sensitivity = cmrr[0]\n",
    "                precision = cmrr[1]\n",
    "\n",
    "                cursor.execute(\"INSERT INTO VV{}(feature_1, p_value_feature_1, feature_2, p_value_feature_2, rand, train_score, test_score, gamma, C, sensitivity, precision_col, ttest) values('{}', {}, '{}', {}, {}, {}, {}, {}, {}, {}, {}, {})\".format(time_string, train_f1, cbi2[0], train_f2, cbi2[1], iui, train_s, test_s, par['gamma'], par['C'], sensitivity, precision, ))\n",
    "                conn.commit()\n",
    "\n",
    "                # acc_plot(test_feas, test_labels, train_feas, train_labels, csc)\n",
    "                \n",
    "                # ROCP(test_feas, test_labels, csc, a= 0)\n",
    "    # except:\n",
    "    #     pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_plot(data_fea, data_label, train_fea, train_label,  model, h = 0.02, bound= 1,  **params):\n",
    "    from matplotlib.patches import Patch\n",
    "\n",
    "    # plot function\n",
    "    #===========================================#\n",
    "    #用途: 畫出邊界plot\n",
    "\n",
    "    #切記: 二維才能畫圖\n",
    "    #===========================================#\n",
    "    # Import: \n",
    "    # numpy\n",
    "    # matplotlib.pyplot\n",
    "    #===========================================#\n",
    "\n",
    "    plt.style.use('seaborn-white')\n",
    "\n",
    "    if len(data_fea.columns) == 2:\n",
    "        def make_meshgrid(x1, x2, h = h):\n",
    "            x_min, x_max = x1.min() - bound, x1.max() + bound - 0.5\n",
    "            y_min, y_max = x2.min() - bound +1, x2.max() + bound - 0.5\n",
    "            xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "            return xx, yy\n",
    "\n",
    "        def plot_contours(clf, xx, yy, ax, **params ):\n",
    "            z = clf.predict(np.c_[xx.ravel(), yy.ravel()])  #np.c_ 帥爛\n",
    "            z = z.reshape(xx.shape)\n",
    "            ax.contourf(xx, yy, z, alpha= 0.8, cmap = plt.cm.coolwarm)\n",
    "            ax.set_xlim(xx.min(), xx.max())\n",
    "            ax.set_ylim(yy.min(), yy.max())\n",
    "            \n",
    "        sns.set(font_scale=1.4)\n",
    "        legend_elements = [Patch(facecolor=(0.2298057, 0.298717966, 0.753683153), label='Low'), Patch(facecolor=(0.705673158, 0.01555616, 0.150232812), label='High')]\n",
    "\n",
    "        fig, (ax2, ax1) = plt.subplots(1, 2, figsize= (12, 6))\n",
    "        xx, yy = make_meshgrid(data_fea.iloc[:, 0],  data_fea.iloc[:, 1])\n",
    "        plot_contours(model, xx, yy, cmap=plt.cm.coolwarm, ax= ax1,  **params)\n",
    "        ax1.scatter(data_fea.iloc[:, 0], data_fea.iloc[:, 1], c= data_label, cmap=plt.cm.coolwarm)  # 用label拚座標，暈爛\n",
    "        ax1.set_xlabel(data_fea.columns[0])\n",
    "        ax1.set_ylabel(data_fea.columns[1])\n",
    "        ax1.set_title(f\"VV Group {model.__class__.__name__} Accuracy: {accuracy_score(test_labels, model.predict(data_fea)):.3f} (Test)\")\n",
    "        ax1.legend(handles=legend_elements, loc= 2)\n",
    "\n",
    "        # plt.show()\n",
    "\n",
    "        # plt.figure(figsize= (6, 6))\n",
    "        plot_contours(model, xx, yy, cmap=plt.cm.coolwarm, ax= ax2, **params)\n",
    "        ax2.scatter(train_fea.iloc[:, 0], train_fea.iloc[:, 1], c= train_label, cmap=plt.cm.coolwarm)  # 用label拚座標，暈爛\n",
    "        ax2.set_xlabel(train_fea.columns[0])\n",
    "        ax2.set_ylabel(train_fea.columns[1])\n",
    "        ax2.set_title(f\"VV Group {model.__class__.__name__} Accuracy: {accuracy_score(train_label, model.predict(train_fea)):.3f} (Train)\")\n",
    "        plt.tight_layout()    \n",
    "\n",
    "        # Create the figure\n",
    "\n",
    "        ax2.legend(handles=legend_elements, loc= 2)\n",
    "\n",
    "\n",
    "        # plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    else: \n",
    "        print(\"Data should be two dimension!!\")\n",
    "\n",
    "        pass\n",
    "\n",
    "    #==================R=O=C===================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Stage2_different_HBO |            0.0082 | Stage3_different_HBO |            0.0223 | 1375 |      0.8788 |     0.8182 | 1.0000 | 100.0000 |      0.8750 |        0.8750 |\n",
    "train_feas, train_labels, test_feas, test_labels = Starifieds(feature, label, random_state=1375, n_splits=4, shuffle= True)\n",
    "\n",
    "train_feas, test_feas = train_feas[[\"Stage2_different_HBO\", \"Stage3_different_HBO\"]], test_feas[[\"Stage2_different_HBO\", \"Stage3_different_HBO\"]]\n",
    "# ====================\n",
    "# print(train_feas.columns)\n",
    "for imm in train_feas.columns:  \n",
    "    if 'std' not in imm:     \n",
    "        sd = StandardScaler()\n",
    "        train_feasn = sd.fit_transform(train_feas[imm].values.reshape(-1,1))\n",
    "        test_feasn = sd.transform(test_feas[imm].values.reshape(-1,1))\n",
    "\n",
    "        train_feas[imm] = train_feasn\n",
    "        test_feas[imm] = test_feasn\n",
    "\n",
    "    # print(f'trans {imm}')\n",
    "# print(test_feas)\n",
    "# ===================================\n",
    "\n",
    "\n",
    "\n",
    "csc = SVC(probability=True, gamma= 1, C= 100)                          \n",
    "\n",
    "#gc = GridSearchCV(csc, params, cv= 5, n_jobs= -1, scoring= 'accuracy')\n",
    "csc.fit(train_feas, train_labels)\n",
    "train_s = accuracy_score(train_labels, csc.predict(train_feas))\n",
    "test_s = accuracy_score(test_labels, csc.predict(test_feas))\n",
    "\n",
    "\n",
    "\n",
    "acc_plot(test_feas, test_labels, train_feas, train_labels, csc, bound= 1.9)\n",
    "condusion_m(train_feas, train_labels, csc, types = 'Train')\n",
    "cm_cr = condusion_m(test_feas, test_labels, csc)\n",
    "print('sensitivity, precision : ', cm_cr)\n",
    "\n",
    "# ROCP(test_feas, test_labels, csc, a= 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
