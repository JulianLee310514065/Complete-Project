{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本project目標\n",
    "\n",
    "1. 定義 Label\n",
    " * 1. Only use CBI1, CBI2, HADS_A, HADAS_B\n",
    " * 2. Define for high and low  \n",
    "    ```\n",
    "    High Score: \n",
    "      CBI >= 16\n",
    "      HADS >= 8\n",
    "    ```\n",
    "2. EDA/ plot\n",
    "\n",
    "3. feature selection (extraction 已做好) + Classfied + Plot margin and confussion matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature = pd.read_excel(\"Features.xlsx\")\n",
    "df_feature\n",
    "# # dropna 補齊excel格式跑掉\n",
    "df_feature_cl = df_feature.dropna()\n",
    "df_feature_cl = df_feature_cl.rename(columns=  {'Unnamed: 0':'Name'})\n",
    "df_feature_cl =  df_feature_cl.set_index('Name')\n",
    "df_feature_cl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認乾淨\n",
    "print(\"Feature DataFrame Shape: \", df_feature_cl.shape)\n",
    "print(\"\\n\\nNull Value:\\n\", df_feature_cl.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀label\n",
    "df_label = pd.read_excel(\"label.xlsx\")\n",
    "df_label = df_label.T\n",
    "\n",
    "# 把第一水平行放到columns\n",
    "df_label.columns = df_label.iloc[0]\n",
    "df_label = df_label.iloc[1:]\n",
    "\n",
    "# 移除CBI_3、CBI_4\n",
    "df_label = df_label.drop(columns= ['CBI_3', 'CBI_4'])\n",
    "print(df_label.shape)\n",
    "df_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply用的function\n",
    "def change(x):\n",
    "    if x >= 16:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def change_hade(x):\n",
    "    if x >= 8:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0       \n",
    "\n",
    "# 處理CBI1跟CBI2\n",
    "change_list = [\"CBI_1\", \"CBI_2\"]\n",
    "for col in change_list:\n",
    "    df_label[col + \"_label\"] = df_label[col].apply(change)\n",
    "    df_label.drop(columns= col, inplace= True)\n",
    "\n",
    "# 處理A_score跟D_score\n",
    "change_list2 = [\"A score\", \"D score\"]\n",
    "for col in change_list2:\n",
    "    df_label[col + \"_label\"] = df_label[col].apply(change_hade)\n",
    "    df_label.drop(columns= col, inplace= True)\n",
    "\n",
    "df_label.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# boxplot - 高低分對年紀的比較\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot\n",
    "plt.figure(figsize= (10, 10))\n",
    "for i, col_p in enumerate([\"CBI_1_label\", \"CBI_2_label\", \"A score_label\", \"D score_label\"]):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    # sns.set_theme(style=\"whitegrid\")\n",
    "    sns.boxplot(x= col_p, y='Age', data= df_label)\n",
    "    plt.title(col_p + \" score-age\")\n",
    "    plt.xticks([0, 1], ['Low', 'High'])\n",
    "    plt.tight_layout()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# countplot - 高低分對性別的比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (10, 10))\n",
    "\n",
    "for i, col_p in enumerate([\"CBI_1_label\", \"CBI_2_label\", \"A score_label\", \"D score_label\"]):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.countplot(x= col_p, data= df_label, hue= 'Gender', palette= ['r', 'b'])\n",
    "    plt.title(col_p + \" score-gender\")\n",
    "    plt.xticks([0, 1], ['Low', 'High'])\n",
    "    plt.legend(loc='upper left', labels=['Female', 'Male'])\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重要!! - inner join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge ，用 inner ，人名一樣的才會上\n",
    "dfs = pd.merge(df_feature_cl, df_label, left_index= True, right_index= True)\n",
    "print(dfs.shape)\n",
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_cl = dfs.loc[:, :'CH3_Deoxy_recovery_auc']\n",
    "df_label = dfs.loc[:, 'Gender':]\n",
    "df_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name 放回來，我也不知道為啥要放回來，當初寫有放回來?\n",
    "\n",
    "# df_feature_cl = df_feature_cl.reset_index()\n",
    "# df_feature_cl = df_feature_cl.rename(columns={'index':'Name'})\n",
    "# df_feature_cl.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection + Model + Plot margin and confussion matrix \n",
    "\n",
    "* ### Feature selection\n",
    "    * 爆幹難，方法百百種，沒有標準答案\n",
    "    * 大致有 選擇 : [Filter](https://ithelp.ithome.com.tw/articles/10245037)、[Wrapper](https://ithelp.ithome.com.tw/articles/10246251)、[Embedded](https://ithelp.ithome.com.tw/articles/10246876)\n",
    "    * 以及 降維度 : PCA、LDA\n",
    "    * [referance](https://www.itread01.com/content/1516714703.html)\n",
    "    * 或者，資料少且需要特徵少 -> 排列組合\n",
    "\n",
    "* ### Model \n",
    "    * 小難，種類也百百種，每年一直出新的\n",
    "    * 但其實好抓，小數具有小數據該用的，大數據亦然\n",
    "    * 小量數據: KNN、SVM、...?LDA?，然後信不信RandomForestTree讓你train_accuracy = 1\n",
    "    * 大量數據: 諸多大招可用，sklearn.ensemble (是一個合集不是一個model)，ML界史爾特爾 XGB & LightGMB，linear界大佬SGD (最近有MSGD但沒有包，要手刻，手刻過DNN的人可以試試)\n",
    "    * ### *推薦資料量不大時用GridSearchCV找參數*\n",
    "    * p.s. 大量數據時不代表\"簡單\"model不可用，Lasso有時會神經刀一波\n",
    "\n",
    "* ### Plot\n",
    "    * 就畫圖，有手就行，但是Excel不行\n",
    "    * Plot margin -> mesh + grid 疊圖 train/test point\n",
    "    * Confussion Matrix -> 包好的\n",
    "    * ROC/AUC -> 包好的\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_feature = df_label[[\"CBI_1_label\", \"CBI_2_label\", \"A score_label\", \"D score_label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# StarifiedKfold\n",
    "def Starifieds(df_feature_cl, pure_feature, random_state= 42, n_splits= 4, shuffle= True):\n",
    "\n",
    "    #======================================\n",
    "    # 用處: Starifieds Kflod 原本只能出index，這裡二合一\n",
    "    #\n",
    "    # Parameter: \n",
    "    #     df_feature_cl, feature\n",
    "    #     pure_feature, label\n",
    "    #     random_state= 42, 不必多說\n",
    "    #     n_splits= 4,  分幾份\n",
    "    #     shuffle= True  如字面上\n",
    "    #======================================\n",
    "\n",
    "    # 先創StratifiedKFold 然後再 .split() 然後取第一個\n",
    "    xtrain, xtest = list(StratifiedKFold(n_splits= n_splits, shuffle= shuffle, random_state= random_state).split(df_feature_cl, pure_feature))[0]\n",
    "\n",
    "    # 把index(用iloc給row的方式)\n",
    "    train_fea, test_fea = df_feature_cl.iloc[xtrain], df_feature_cl.iloc[xtest]\n",
    "    train_label, test_label = pure_feature.iloc[xtrain], pure_feature.iloc[xtest]\n",
    "\n",
    "    #===============\n",
    "    \n",
    "    # 不知道為啥以前留有Gender\n",
    "    try:\n",
    "        train_fea.drop(columns= [\"Gender\"], inplace=True)\n",
    "        test_fea.drop(columns= [\"Gender\"], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return train_fea, train_label, test_fea, test_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_plot(test_feature, test_label, train_fea, train_label,  model, h = 0.02, bound= 1,  **params):\n",
    "\n",
    "    # plot function\n",
    "    #===========================================#\n",
    "    #用途: 畫出邊界plot\n",
    "    \n",
    "    #切記: 二維才能畫圖\n",
    "    #===========================================#\n",
    "    # Import: \n",
    "    # numpy\n",
    "    # matplotlib.pyplot\n",
    "    #===========================================#\n",
    "\n",
    "    # 白底\n",
    "    plt.style.use('seaborn-white')\n",
    "    sns.set(font_scale=1.4)\n",
    "\n",
    "    # 確定是二維\n",
    "    if len(test_feature.columns) == 2:\n",
    "        # 把網格架好\n",
    "        def make_meshgrid(x1, x2, h = h):\n",
    "            x_min, x_max = x1.min() - bound, x1.max() + bound\n",
    "            y_min, y_max = x2.min() - bound, x2.max() + bound\n",
    "            xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "            return xx, yy\n",
    "        \n",
    "        # 畫出等高線\n",
    "        def plot_contours(clf, xx, yy, ax, **params ):\n",
    "            z = clf.predict(np.c_[xx.ravel(), yy.ravel()])  #np.c_ 帥爛\n",
    "            z = z.reshape(xx.shape)\n",
    "            ax.contourf(xx, yy, z, alpha= 0.8, cmap = plt.cm.coolwarm)\n",
    "            ax.set_xlim(xx.min(), xx.max())\n",
    "            ax.set_ylim(yy.min(), yy.max())\n",
    "                        \n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize= (12, 6))\n",
    "\n",
    "        # 要用test的 還是train的\n",
    "        xx, yy = make_meshgrid(test_feature.iloc[:, 0],  test_feature.iloc[:, 1])\n",
    "        \n",
    "\n",
    "        plot_contours(model, xx, yy, cmap=plt.cm.coolwarm, ax= ax1, **params)\n",
    "        ax1.scatter(train_fea.iloc[:, 0], train_fea.iloc[:, 1], c= train_label, cmap=plt.cm.coolwarm)  # 用label拚座標，暈爛\n",
    "        ax1.set_xlabel(train_fea.columns[0])\n",
    "        ax1.set_ylabel(train_fea.columns[1])\n",
    "        ax1.set_title(f\"{model.__class__.__name__} Train Plot {accuracy_score(train_label, model.predict(train_fea))}\")\n",
    "\n",
    "\n",
    "        plot_contours(model, xx, yy, cmap=plt.cm.coolwarm, ax= ax2,  **params)\n",
    "        ax2.scatter(test_feature.iloc[:, 0], test_feature.iloc[:, 1], c= test_label, cmap=plt.cm.coolwarm)  # 用label拚座標，暈爛\n",
    "        ax2.set_xlabel(test_feature.columns[0])\n",
    "        ax2.set_ylabel(test_feature.columns[1])\n",
    "        ax2.set_title(f\"{model.__class__.__name__} Test Plot {accuracy_score(test_label, model.predict(test_feature))}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    else: \n",
    "        print(\"Data should be two dimension!!\")\n",
    "\n",
    "        # pass\n",
    "\n",
    "    #==================R=O=C===================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condusion_m(test_fea, test_label, model):\n",
    "\n",
    "    #=============================\n",
    "    # 用途: \n",
    "    #     製造出confusion matrix\n",
    "\n",
    "    # Parameter:\n",
    "    #     test_fea  就feature\n",
    "    #     test_label  就label\n",
    "    #     model  就model\n",
    "    #=============================\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    conf = confusion_matrix(test_label, model.predict(test_fea))\n",
    "    conp = np.array([(x/sum(x)) for x in conf])\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize= (14, 7))\n",
    "    # 重點是 annot，cmap='Blues'\n",
    "    sns.set(font_scale=1.8)\n",
    "    sns.heatmap(conp , annot= True, cmap='Blues', ax= ax1)\n",
    "    ax1.set_title(f\"CM of {model.__class__.__name__}\")\n",
    "\n",
    "    sns.heatmap(conf , annot= True, cmap='Blues', ax= ax2)\n",
    "    ax2.set_title(f\"CM of {model.__class__.__name__}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROCP(test_fea, test_label, model, a= 0, pos_label= 0):\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "    #=============================\n",
    "    # 用途: \n",
    "    #     製造出confusion matrix\n",
    "\n",
    "    # Parameter:\n",
    "    #     test_fea  就feature\n",
    "    #     test_label  就label\n",
    "    #     model  就model\n",
    "    #     a= 0 如果auc很奇怪，就 =1 \n",
    "    #=============================\n",
    "\n",
    "    try:\n",
    "        prob = model.predict_proba(test_fea)[:, a]\n",
    "        sns.set(font_scale=1.4)\n",
    "        fig, ax= plt.subplots(1, 1, figsize= (8, 7))\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(test_label, prob, pos_label= pos_label)  #pos_label= 0 要設值\n",
    "        plt.plot(fpr, tpr,   color= 'b', linewidth=3.0)\n",
    "\n",
    "        \n",
    "        x, y = np.arange(0, 1, 0.01), np.arange(0, 1, 0.01)\n",
    "        plt.plot(x, y, '-.', linewidth=3.0, label= f\"AUC  = {auc(fpr, tpr)}\", color= 'r')\n",
    "        \n",
    "        ax.set_xlabel(\" 1 - specificity\")\n",
    "        ax.set_ylabel(\"Sensitivity\")\n",
    "        ax.set_title(f\"{model.__class__.__name__}'s  ROC\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    except:\n",
    "        print(\"Can't print ROC\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ttest(with standardscaler) + SVC + plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 統計法\n",
    "### [# 看這裡](https://statistics-using-python.blogspot.com/2019/08/blog-post.html)\n",
    "\n",
    "\n",
    "## ttest\n",
    "\n",
    "[這裡](https://statistics-using-python.blogspot.com/2019/08/t-two-sample-t-test-with-equal.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "# feature selection\n",
    "\n",
    "\n",
    "\n",
    "def ttttest(train_fea, train_label):\n",
    "\n",
    "    #======================================================\n",
    "    # 1. scipy.stats.shapiro\n",
    "\n",
    "\n",
    "    shap_low = []\n",
    "    shap_high = []\n",
    "    shap_cols = []\n",
    "\n",
    "    all_fea = train_fea.merge(train_label, left_index= True, right_index= True)\n",
    "    all_fea = all_fea.sort_values(by= train_label.name)\n",
    "\n",
    "    # print(train_label.name)\n",
    "\n",
    "    cols = all_fea.columns\n",
    "    #print(cols)\n",
    "\n",
    "    all_low = all_fea[all_fea[train_label.name] == 0]\n",
    "    all_high = all_fea[all_fea[train_label.name] == 1]\n",
    "\n",
    "    for col in cols:\n",
    "        # 看p_value 可不留\n",
    "        lows = scipy.stats.shapiro(all_low[col])[1]\n",
    "        highs = scipy.stats.shapiro(all_high[col])[1]\n",
    "\n",
    "        shap_low.append(lows)\n",
    "        shap_high.append(highs)\n",
    "\n",
    "        if lows > 0.05 and highs > 0.05:\n",
    "            shap_cols.append(col)\n",
    "\n",
    "    shap_cols\n",
    "    #=====================================================\n",
    "    # 2.scipy.stats.levene\n",
    "\n",
    "    levene = []\n",
    "    good_levene = []\n",
    "\n",
    "    for shapiro_col in shap_cols:\n",
    "\n",
    "        lev = scipy.stats.levene(all_low[shapiro_col], all_high[shapiro_col], center = 'mean')[1]  \n",
    "        levene.append(lev)\n",
    "\n",
    "        if lev > 0.05:\n",
    "            good_levene.append(shapiro_col)\n",
    "\n",
    "    good_levene\n",
    "\n",
    "    #======================================================\n",
    "    # 3. scipy.stats.ttest_ind\n",
    "    \n",
    "    ttest = []\n",
    "    good_ttest = []\n",
    "\n",
    "\n",
    "    for good_lev in good_levene:\n",
    "        ttestn = scipy.stats.ttest_ind(all_low[good_lev], all_high[good_lev], equal_var = True)[1]\n",
    "        ttest.append(ttestn)\n",
    "\n",
    "    #display results\n",
    "    ttest_df = pd.Series(ttest, index= good_levene, name= train_label.name + '_T_score').sort_values()\n",
    "    return ttest_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找個pretty ttest score\n",
    "# 先ttest 再標準化\n",
    "\n",
    "for rand in range(10):\n",
    "    train_fea2, train_label2, test_fea2, test_label2 = Starifieds(df_feature_cl, pure_feature[\"CBI_1_label\"], random_state= rand)\n",
    "\n",
    "    cbi2 = ttttest(train_fea2, train_label2)\n",
    "    # print(cbi2)\n",
    "    if cbi2[0] < 0.05 and cbi2[1] < 0.05:\n",
    "        print(\"rand \", rand, \"\\n\", cbi2[:2], end= '\\n\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 測試結果:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CBI 1 \n",
    "train_feas, train_labels, test_feas, test_labels = Starifieds(df_feature_cl, pure_feature[\"CBI_1_label\"], random_state= 42)\n",
    "cbi2 = ttttest(train_feas, train_labels)\n",
    "train_feas, test_feas = train_feas[cbi2.index[:2]], test_feas[cbi2.index[:2]]\n",
    "\n",
    "\n",
    "# ====================\n",
    "# print(train_feas.columns)\n",
    "for imm in train_feas.columns:\n",
    "    if 'std' not in imm:     \n",
    "        sd = StandardScaler()\n",
    "        train_feasn = sd.fit_transform(train_feas[imm].values.reshape(-1,1))\n",
    "        test_feasn = sd.transform(test_feas[imm].values.reshape(-1,1))\n",
    "\n",
    "        train_feas[imm] = train_feasn\n",
    "        test_feas[imm] = test_feasn\n",
    "\n",
    "        # print(f'trans {imm}')\n",
    "# print(test_feas)\n",
    "# ===================================\n",
    "\n",
    "\n",
    "csc = SVC(probability=True, gamma= 1, C= 100)                          \n",
    "csc.fit(train_feas, train_labels)\n",
    "train_s = accuracy_score(train_labels, csc.predict(train_feas))\n",
    "test_s = accuracy_score(test_labels, csc.predict(test_feas))\n",
    "print(cbi2[:2])\n",
    "print('train ', train_s)\n",
    "print('test', test_s)\n",
    "print(\"param C = \", csc.get_params()[\"C\"], \"param gamma = \", csc.get_params()[\"gamma\"])\n",
    "\n",
    "acc_plot(test_feas, test_labels, train_feas, train_labels, csc, bound = 0.2)\n",
    "condusion_m(test_feas, test_labels, csc)\n",
    "ROCP(test_feas, test_labels, csc, a= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CBI 2 \n",
    "train_feas, train_labels, test_feas, test_labels = Starifieds(df_feature_cl, pure_feature[\"CBI_2_label\"], random_state= 42)\n",
    "cbi2 = ttttest(train_feas, train_labels)\n",
    "train_feas, test_feas = train_feas[cbi2.index[:2]], test_feas[cbi2.index[:2]]\n",
    "\n",
    "# ====================\n",
    "# print(train_feas.columns)\n",
    "for imm in train_feas.columns:\n",
    "    if 'std' not in imm:     \n",
    "        sd = StandardScaler()\n",
    "        train_feasn = sd.fit_transform(train_feas[imm].values.reshape(-1,1))\n",
    "        test_feasn = sd.transform(test_feas[imm].values.reshape(-1,1))\n",
    "\n",
    "        train_feas[imm] = train_feasn\n",
    "        test_feas[imm] = test_feasn\n",
    "\n",
    "        # print(f'trans {imm}')\n",
    "# print(test_feas)\n",
    "# ===================================\n",
    "\n",
    "\n",
    "csc = SVC(probability=True, gamma= 1, C= 100)                          \n",
    "csc.fit(train_feas, train_labels)\n",
    "train_s = accuracy_score(train_labels, csc.predict(train_feas))\n",
    "test_s = accuracy_score(test_labels, csc.predict(test_feas))\n",
    "print(cbi2[:2])\n",
    "print('train ', train_s)\n",
    "print('test', test_s)\n",
    "print(\"param: C = \", csc.get_params()[\"C\"], \", param: gamma = \", csc.get_params()[\"gamma\"])\n",
    "\n",
    "acc_plot(test_feas, test_labels, train_feas, train_labels, csc, bound = 0.2)\n",
    "condusion_m(test_feas, test_labels, csc)\n",
    "ROCP(test_feas, test_labels, csc, a= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"D score_label\" \n",
    "train_feas, train_labels, test_feas, test_labels = Starifieds(df_feature_cl, pure_feature[\"D score_label\"], random_state= 42)\n",
    "cbi2 = ttttest(train_feas, train_labels)\n",
    "train_feas, test_feas = train_feas[cbi2.index[:2]], test_feas[cbi2.index[:2]]\n",
    "\n",
    "# ====================\n",
    "# print(train_feas.columns)\n",
    "for imm in train_feas.columns:\n",
    "    if 'std' not in imm:     \n",
    "        sd = StandardScaler()\n",
    "        train_feasn = sd.fit_transform(train_feas[imm].values.reshape(-1,1))\n",
    "        test_feasn = sd.transform(test_feas[imm].values.reshape(-1,1))\n",
    "\n",
    "        train_feas[imm] = train_feasn\n",
    "        test_feas[imm] = test_feasn\n",
    "\n",
    "        # print(f'trans {imm}')\n",
    "# print(test_feas)\n",
    "# ===================================\n",
    "\n",
    "csc = SVC(probability=True, gamma= 1, C= 100)                          \n",
    "csc.fit(train_feas, train_labels)\n",
    "train_s = accuracy_score(train_labels, csc.predict(train_feas))\n",
    "test_s = accuracy_score(test_labels, csc.predict(test_feas))\n",
    "print(cbi2[:2])\n",
    "print('train ', train_s)\n",
    "print('test', test_s)\n",
    "print(\"param C = \", csc.get_params()[\"C\"], \"param gamma = \", csc.get_params()[\"gamma\"])\n",
    "\n",
    "acc_plot(test_feas, test_labels, train_feas, train_labels, csc, bound= 0.2)\n",
    "condusion_m(test_feas, test_labels, csc)\n",
    "ROCP(test_feas, test_labels, csc, a= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"A score_label\" \n",
    "train_feas, train_labels, test_feas, test_labels = Starifieds(df_feature_cl, pure_feature[\"A score_label\"], random_state= 42)\n",
    "cbi2 = ttttest(train_feas, train_labels)\n",
    "train_feas, test_feas = train_feas[cbi2.index[:2]], test_feas[cbi2.index[:2]]\n",
    "\n",
    "# ====================\n",
    "# print(train_feas.columns)\n",
    "for imm in train_feas.columns:\n",
    "    if 'std' not in imm:     \n",
    "        sd = StandardScaler()\n",
    "        train_feasn = sd.fit_transform(train_feas[imm].values.reshape(-1,1))\n",
    "        test_feasn = sd.transform(test_feas[imm].values.reshape(-1,1))\n",
    "\n",
    "        train_feas[imm] = train_feasn\n",
    "        test_feas[imm] = test_feasn\n",
    "\n",
    "        # print(f'trans {imm}')\n",
    "# print(test_feas)\n",
    "# ===================================\n",
    "\n",
    "csc = SVC(probability=True, gamma= 1, C= 1)                          \n",
    "csc.fit(train_feas, train_labels)\n",
    "train_s = accuracy_score(train_labels, csc.predict(train_feas))\n",
    "test_s = accuracy_score(test_labels, csc.predict(test_feas))\n",
    "print(cbi2[:2])\n",
    "print('train ', train_s)\n",
    "print('test', test_s)\n",
    "print(\"param C = \", csc.get_params()[\"C\"], \"param gamma = \", csc.get_params()[\"gamma\"])\n",
    "\n",
    "acc_plot(test_feas, test_labels, train_feas, train_labels, csc, bound= 0.2)\n",
    "condusion_m(test_feas, test_labels, csc)\n",
    "ROCP(test_feas, test_labels, csc, a= 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 樹的feature important + SVC + plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 測試結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CBI1\n",
    "train_feas, train_labels, test_feas, test_labels = Starifieds(df_feature_cl, pure_feature[\"CBI_1_label\"], random_state= 42)\n",
    "\n",
    "train_feas = train_feas.drop(columns = \"Name\")\n",
    "test_feas = test_feas.drop(columns = \"Name\")\n",
    "\n",
    "# print(train_feas.columns.shape)\n",
    "\n",
    "coll = train_feas.columns\n",
    "\n",
    "rfc = RandomForestClassifier(random_state= 42)\n",
    "rfc.fit(train_feas, train_labels)\n",
    "    \n",
    "imp = rfc.feature_importances_\n",
    "\n",
    "Se = pd.Series(imp, index= coll).sort_values(ascending= False)\n",
    "\n",
    "train_feas, test_feas = train_feas[Se.index[:2]], test_feas[Se.index[:2]]\n",
    "\n",
    "# ====================\n",
    "# print(train_feas.columns)\n",
    "for imm in train_feas.columns:\n",
    "    if 'std' not in imm:     \n",
    "        sd = StandardScaler()\n",
    "        train_feasn = sd.fit_transform(train_feas[imm].values.reshape(-1,1))\n",
    "        test_feasn = sd.transform(test_feas[imm].values.reshape(-1,1))\n",
    "\n",
    "        train_feas[imm] = train_feasn\n",
    "        test_feas[imm] = test_feasn\n",
    "\n",
    "        # print('go')\n",
    "        # print(f'trans {imm}')\n",
    "# print(test_feas)\n",
    "# ===================================\n",
    "\n",
    "csc = SVC(probability=True, gamma= 0.1, C= 100)                          \n",
    "\n",
    "\n",
    "csc.fit(train_feas, train_labels)\n",
    "train_s = accuracy_score(train_labels, csc.predict(train_feas))\n",
    "test_s = accuracy_score(test_labels, csc.predict(test_feas))\n",
    "\n",
    "print('train ', train_s)\n",
    "print('test', test_s)\n",
    "# print(\"par = \", par)\n",
    "\n",
    "acc_plot(test_feas, test_labels, train_feas, train_labels, csc, bound= 0.5)\n",
    "condusion_m(test_feas, test_labels, csc)\n",
    "ROCP(test_feas, test_labels, csc, a= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D score_label\n",
    "train_feas, train_labels, test_feas, test_labels = Starifieds(df_feature_cl, pure_feature[\"D score_label\"], random_state= 42)\n",
    "train_feas = train_feas.drop(columns = \"Name\")\n",
    "test_feas = test_feas.drop(columns = \"Name\")\n",
    "\n",
    "# print(train_feas.columns.shape)\n",
    "\n",
    "coll = train_feas.columns\n",
    "\n",
    "rfc = RandomForestClassifier(random_state= 42)\n",
    "rfc.fit(train_feas, train_labels)\n",
    "    \n",
    "imp = rfc.feature_importances_\n",
    "\n",
    "Se = pd.Series(imp, index= coll).sort_values(ascending= False)\n",
    "\n",
    "train_feas, test_feas = train_feas[Se.index[:2]], test_feas[Se.index[:2]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ====================\n",
    "# print(train_feas.columns)\n",
    "for imm in train_feas.columns:\n",
    "    if 'std' not in imm:     \n",
    "        sd = StandardScaler()\n",
    "        train_feasn = sd.fit_transform(train_feas[imm].values.reshape(-1,1))\n",
    "        test_feasn = sd.transform(test_feas[imm].values.reshape(-1,1))\n",
    "\n",
    "        train_feas[imm] = train_feasn\n",
    "        test_feas[imm] = test_feasn\n",
    "\n",
    "        # print('go')\n",
    "        # print(f'trans {imm}')\n",
    "# print(test_feas)\n",
    "# ===================================\n",
    "\n",
    "csc = SVC(probability=True, gamma= 0.01, C= 100)                          \n",
    "\n",
    "\n",
    "csc.fit(train_feas, train_labels)\n",
    "train_s = accuracy_score(train_labels, csc.predict(train_feas))\n",
    "test_s = accuracy_score(test_labels, csc.predict(test_feas))\n",
    "\n",
    "print('train ', train_s)\n",
    "print('test', test_s)\n",
    "# print(\"par = \", par)\n",
    "\n",
    "acc_plot(test_feas, test_labels, train_feas, train_labels, csc, bound= 0.75)\n",
    "condusion_m(test_feas, test_labels, csc)\n",
    "ROCP(test_feas, test_labels, csc, a= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A score_label\n",
    "train_feas, train_labels, test_feas, test_labels = Starifieds(df_feature_cl, pure_feature[\"A score_label\"], random_state= 177)\n",
    "train_feas = train_feas.drop(columns = \"Name\")\n",
    "test_feas = test_feas.drop(columns = \"Name\")\n",
    "\n",
    "# print(train_feas.columns.shape)\n",
    "\n",
    "coll = train_feas.columns\n",
    "\n",
    "rfc = RandomForestClassifier(random_state= 42)\n",
    "rfc.fit(train_feas, train_labels)\n",
    "    \n",
    "imp = rfc.feature_importances_\n",
    "\n",
    "Se = pd.Series(imp, index= coll).sort_values(ascending= False)\n",
    "\n",
    "train_feas, test_feas = train_feas[Se.index[:2]], test_feas[Se.index[:2]]\n",
    "\n",
    "# ====================\n",
    "# print(train_feas.columns)\n",
    "for imm in train_feas.columns:\n",
    "    if 'std' not in imm:     \n",
    "        sd = StandardScaler()\n",
    "        train_feasn = sd.fit_transform(train_feas[imm].values.reshape(-1,1))\n",
    "        test_feasn = sd.transform(test_feas[imm].values.reshape(-1,1))\n",
    "\n",
    "        train_feas[imm] = train_feasn\n",
    "        test_feas[imm] = test_feasn\n",
    "\n",
    "        # print('go')\n",
    "        # print(f'trans {imm}')\n",
    "# print(test_feas)\n",
    "# ===================================\n",
    "\n",
    "csc = SVC(probability=True, gamma= 1, C= 100)                          \n",
    "\n",
    "\n",
    "csc.fit(train_feas, train_labels)\n",
    "train_s = accuracy_score(train_labels, csc.predict(train_feas))\n",
    "test_s = accuracy_score(test_labels, csc.predict(test_feas))\n",
    "\n",
    "print('train ', train_s)\n",
    "print('test', test_s)\n",
    "# print(\"par = \", par)\n",
    "\n",
    "acc_plot(test_feas, test_labels, train_feas, train_labels, csc, bound= 0.3)\n",
    "condusion_m(test_feas, test_labels, csc)\n",
    "ROCP(test_feas, test_labels, csc, a= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CBI_2_label\n",
    "train_feas, train_labels, test_feas, test_labels = Starifieds(df_feature_cl, pure_feature[\"CBI_2_label\"], random_state= 42)\n",
    "train_feas = train_feas.drop(columns = \"Name\")\n",
    "test_feas = test_feas.drop(columns = \"Name\")\n",
    "\n",
    "# print(train_feas.columns.shape)\n",
    "\n",
    "coll = train_feas.columns\n",
    "\n",
    "rfc = RandomForestClassifier(random_state= 42)\n",
    "rfc.fit(train_feas, train_labels)\n",
    "    \n",
    "imp = rfc.feature_importances_\n",
    "\n",
    "Se = pd.Series(imp, index= coll).sort_values(ascending= False)\n",
    "\n",
    "train_feas, test_feas = train_feas[Se.index[:2]], test_feas[Se.index[:2]]\n",
    "\n",
    "\n",
    "# ====================\n",
    "# print(train_feas.columns)\n",
    "for imm in train_feas.columns:\n",
    "    if 'std' not in imm:     \n",
    "        sd = StandardScaler()\n",
    "        train_feasn = sd.fit_transform(train_feas[imm].values.reshape(-1,1))\n",
    "        test_feasn = sd.transform(test_feas[imm].values.reshape(-1,1))\n",
    "\n",
    "        train_feas[imm] = train_feasn\n",
    "        test_feas[imm] = test_feasn\n",
    "\n",
    "        # print('go')\n",
    "        # print(f'trans {imm}')\n",
    "# print(test_feas)\n",
    "# ===================================\n",
    "\n",
    "csc = SVC(probability=True, gamma= 1, C= 10)                          \n",
    "\n",
    "\n",
    "csc.fit(train_feas, train_labels)\n",
    "train_s = accuracy_score(train_labels, csc.predict(train_feas))\n",
    "test_s = accuracy_score(test_labels, csc.predict(test_feas))\n",
    "\n",
    "print('train ', train_s)\n",
    "print('test', test_s)\n",
    "# print(\"par = \", par)\n",
    "\n",
    "acc_plot(test_feas, test_labels, train_feas, train_labels, csc, bound= 0.4)\n",
    "condusion_m(test_feas, test_labels, csc)\n",
    "ROCP(test_feas, test_labels, csc, a= 0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
